<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="google-site-verification" content="Qaj1oI-YdwUZuv0leZOLPjdeytx5rFdaC1OehlkFWeg" />

<title>

  Urja Khurana


  | publications

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ’»</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/publications/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
       Urja Khurana
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/cv/">
                cv
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item active">
              <a class="nav-link" href="/publications/">
                publications
                
                <span class="sr-only">(current)</span>
                
              </a>
          </li>
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p>
  </header>

  <article>
    <div class="publications">


  <h2 class="year">2024</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="khurana2024crowdcalibrator" class="col-sm-8">
    
      <div class="title">Crowd-Calibrator: Can Annotator Disagreement Inform Calibration in Subjective Tasks?</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Khurana, Urja</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nalisnick, Eric,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Fokkens, Antske,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Swayamdipta, Swabha
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In First Conference on Language Modeling</em>
      
      
        2024
      
      </div>
    

    <div class="links">
    
    
    
    
      <a href="https://openreview.net/forum?id=VWWzO3ewMS" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2023</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="krause-etal-2023-leveraging" class="col-sm-8">
    
      <div class="title">Leveraging Few-Shot Data Augmentation and Waterfall Prompting for Response Generation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Krause, Lea,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  B{\'a}ez Santamar{\'\i}a, Selene,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Meer, Michiel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                and <em>Khurana, Urja</em>
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of The Eleventh Dialog System Technology Challenge</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://aclanthology.org/2023.dstc-1.22/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper discusses our approaches for task-oriented conversational modelling using subjective knowledge, with a particular emphasis on response generation. Our methodology was shaped by an extensive data analysis that evaluated key factors such as response length, sentiment, and dialogue acts present in the provided dataset. We used few-shot learning to augment the data with newly generated subjective knowledge items and present three approaches for DSTC11: (1) task-specific model exploration, (2) incorporation of the most frequent question into all generated responses, and (3) a waterfall prompting technique using a combination of both GPT-3 and ChatGPT.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="krause-etal-2023-confidently" class="col-sm-8">
    
      <div class="title">Confidently Wrong: Exploring the Calibration and Expression of (Un)Certainty of Large Language Models in a Multilingual Setting</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Krause, Lea,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tufa, Wondimagegnhue,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Baez Santamaria, Selene,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Daza, Angel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Khurana, Urja</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Vossen, Piek
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the Workshop on Multimodal, Multilingual Natural Language Generation and Multilingual WebNLG Challenge (MM-NLG 2023)</em>
      
      
        2023
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://aclanthology.org/2023.mmnlg-1.1" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>While the fluency and coherence of Large Language Models (LLMs) in text generation have seen significant improvements, their competency in generating appropriate expressions of uncertainty remains limited.Using a multilingual closed-book QA task and GPT-3.5, we explore how well LLMs are calibrated and express certainty across a diverse set of languages, including low-resource settings. Our results reveal strong performance in high-resource languages but a marked decline in performance in lower-resource languages. Across all, we observe an exaggerated expression of confidence in the model, which does not align with the correctness or likelihood of its responses. Our findings highlight the need for further research into accurate calibration of LLMs especially in a multilingual setting.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="khurana-etal-2022-hate" class="col-sm-8">
    
      <div class="title">Hate Speech Criteria: A Modular Approach to Task-Specific Hate Speech Definitions</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Khurana, Urja</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vermeulen, Ivar,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nalisnick, Eric,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Van Noorloos, Marloes,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Fokkens, Antske
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH)</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://aclanthology.org/2022.woah-1.17" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The subjectivity of automatic hate speech detection makes it a complex task, reflected in different and incomplete definitions in NLP. We present hate speech criteria, developed with insights from a law and social science expert, that help researchers create more explicit definitions and annotation guidelines on five aspects: (1) target groups and (2) dominance, (3) perpetrator characteristics, (4) explicit presence of negative interactions, and the (5) type of consequences/effects. Definitions can be structured so that they cover a more broad or more narrow phenomenon and conscious choices can be made on specifying criteria or leaving them open. We argue that the goal and exact task developers have in mind should determine how the scope of hate speech is defined. We provide an overview of the properties of datasets from hatespeechdata.com that may help select the most suitable dataset for a specific scenario.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">khurana-etal-2022-hate</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hate Speech Criteria: A Modular Approach to Task-Specific Hate Speech Definitions}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Khurana, Urja and Vermeulen, Ivar and Nalisnick, Eric and Van Noorloos, Marloes and Fokkens, Antske}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Sixth Workshop on Online Abuse and Harms (WOAH)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Seattle, Washington (Hybrid)}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2022.woah-1.17}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2022.woah-1.17}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2022.woah-1.17}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{176--191}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="van-der-meer-etal-2022-will" class="col-sm-8">
    
      <div class="title">Will It Blend? Mixing Training Paradigms {\&amp;} Prompting for Argument Quality Prediction</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Meer, Michiel,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Reuver, Myrthe,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Khurana, Urja</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Krause, Lea,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Baez Santamaria, Selene
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 9th Workshop on Argument Mining</em>
      
      
        2022
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://aclanthology.org/2022.argmining-1.8/" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This paper describes our contributions to the Shared Task of the 9th Workshop on Argument Mining (2022). Our approach uses Large Language Models for the task of Argument Quality Prediction. We perform prompt engineering using GPT-3, and also investigate the training paradigms multi-task learning, contrastive learning, and intermediate-task training. We find that a mixed prediction setup outperforms single models. Prompting GPT-3 works best for predicting argument validity, and argument novelty is best estimated by a model trained using all three training paradigms.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="khurana-etal-2021-emotionally" class="col-sm-8">
    
      <div class="title">How Emotionally Stable is {ALBERT}? Testing Robustness with Stochastic Weight Averaging on a Sentiment Analysis Task</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Khurana, Urja</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nalisnick, Eric,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Fokkens, Antske
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://aclanthology.org/2021.eval4nlp-1.3" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Despite their success, modern language models are fragile. Even small changes in their
                training pipeline can lead to unexpected results. We study this phenomenon by examining the robustness of ALBERT (Lan
                et al., 2020) in combination with Stochastic Weight Averaging (SWA)â€”a cheap way
                of ensemblingâ€”on a sentiment analysis task
                (SST-2). In particular, we analyze SWAâ€™s stability via CheckList criteria (Ribeiro et al.,
                2020), examining the agreement on errors
                made by models differing only in their random
                seed. We hypothesize that SWA is more stable
                because it ensembles model snapshots taken
                along the gradient descent trajectory. We quantify stability by comparing the modelsâ€™ mistakes with Fleissâ€™ Kappa (Fleiss, 1971) and
                overlap ratio scores. We find that SWA reduces error rates in general; yet the models
                still suffer from their own distinct biases (according to CheckList).
                </p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">khurana-etal-2021-emotionally</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{How Emotionally Stable is {ALBERT}? Testing Robustness with Stochastic Weight Averaging on a Sentiment Analysis Task}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Khurana, Urja and Nalisnick, Eric and Fokkens, Antske}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2nd Workshop on Evaluation and Comparison of NLP Systems}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Punta Cana, Dominican Republic}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2021.eval4nlp-1.3}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2021.eval4nlp-1.3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{16--31}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="khurana2017linguistic" class="col-sm-8">
    
      <div class="title">The linguistic features of fake news headlines and statements</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Khurana, Urja</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Intelligentie, Bachelor Opleiding Kunstmatige
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://scripties.uba.uva.nl/search?id=633521" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The recent rise of fake news has heavily influenced people. From the 2016 US Presidential Elections to Pizzagate. Thus, it is essential to address this socially relevant phenomenon. Until now, most of the research done was related to satire and clickbait. This thesis explores the linguistic features that are able to distinguish between fake and real news headlines and statements. By extracting different linguistic features of statements and headlines, the predictive power of each different feature is explored. Using classifiers, the overall approach is discussed. It appears that unigrams, POS tag sequences, punctuation and generality are some of the features that have the most predictive power. In the end, the performances were above baseline.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">khurana2017linguistic</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The linguistic features of fake news headlines and statements}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Khurana, Urja and Intelligentie, Bachelor Opleiding Kunstmatige}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://scripties.uba.uva.nl/search?id=633521}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
  </div>

  <div id="Khurana2017CookinIC" class="col-sm-8">
    
      <div class="title">Cookinâ€™: Interactive Cooking Assistant</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Alberts, Houda,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Khurana, Urja</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Tjhia, Melissa,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Olij, Richard
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In </em>
      
      
        2017
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
        <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
    
    
      <a href="https://www.semanticscholar.org/paper/Cookin%E2%80%99%3A-Interactive-Cooking-Assistant-Khurana-Tjhia/520b27ed7aa4a72ca6a329c7010de9b5530706d3" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>This report focuses on an interactive system that helps people during cooking by guiding them through the steps of a recipe which is obtained with the Spoonacular API. This involves both text and speech instructions that the system gives to the user, while the user can interact with it by using their voice and poses. In literature, these systems have been explored before, but only certain parts were implemented or it only gave limited feedback during cooking. This system guides a user completely through the process by reading out the equipment, ingredients and steps. Each multimedia component, speech and visuals, will be explored separately and then each component will be connected to the actual system by a user interface. This results in a system that works with textual input at the start, and voice commands and poses during the process where machine learning is used for the recognition of poses and the speech is made more efficient by using more words to recognize commands. Speech recognition is done with the Google Speech Recognition API and Kinect is used for the detection of the joint coordinates of poses. Training is done on a dataset which contains the arm coordinates and that can be extended. For classifying, the k-nearest neighbor algorithm was used since it gives the highest accuracy (99.76%) and is also relatively fast. The value for k is chosen to be 8, based on the amount of poses and a noise class. In the future, other multimedia components can be added to the infrastructure, since it is easily adjustable.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
    <div class="bibtex hidden">
      <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Khurana2017CookinIC</span><span class="p">,</span>
  <span class="na">bibtex_show</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cookinâ€™: Interactive Cooking Assistant}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Alberts, Houda and Khurana, Urja and Tjhia, Melissa and Olij, Richard}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">html</span> <span class="p">=</span> <span class="s">{https://www.semanticscholar.org/paper/Cookin%E2%80%99%3A-Interactive-Cooking-Assistant-Khurana-Tjhia/520b27ed7aa4a72ca6a329c7010de9b5530706d3}</span>
<span class="p">}</span></code></pre></figure>
    </div>
    
  </div>
</div>
</li></ol>


</div>

  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2024 Urja  Khurana.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
